# References of Decentralized-Stochastic-Optimization 
A references list of papers dedicated to decentralized stochastic optimization

# Contents

 - [Angelia Nedic](#angelia-nedic)
 - [Ali Sayed](#ali-sayed)
 - [Mingyi Hone](#mingyi-hong)
 - [Michal Rabbat](#michal-rabbat)
 - [Guanghui Lan](#guanghui-lan)
 - [Ji Liu](#ji-liu)
 - [Martin Jaggi](#martin-jaggi)
 - [Other authors](#other-authors)

## Angelia Nedic

* Distributed Stochastic Subgradient Projection Algorithms for Convex Optimization, 2010,
https://arxiv.xilesou.top/abs/0811.2595

## Ali Sayed

* Variance-Reduced Stochastic Learning by Networked Agents Under Random Reshuffling, 2019,
https://arxiv.xilesou.top/abs/1708.01384

## Mingyi Hong

## Michal Rabbat

* Multi-agent mirror descent for decentralized stochastic optimization, 2015,
https://ieeexplore.ieee.org/document/7383850/

## Guanghui Lan

* Communication-efficient algorithms for decentralized and stochastic optimization, 2017,
https://arxiv.xilesou.top/abs/1701.03961

## Ji Liu

* Can Decentralized Algorithms Outperform Centralized Algorithms? A Case Study for Decentralized Parallel Stochastic Gradient Descent, 2017,
https://arxiv.xilesou.top/abs/1705.09056

* Asynchronous Decentralized Parallel Stochastic Gradient Descent. 2017,
https://arxiv.xilesou.top/abs/1710.06952

* D<sup>2</sup>: Decentralized Training over Decentralized Data, 2018,
https://arxiv.xilesou.top/abs/1803.07068

## Martin Jaggi

* A Unified Theory of Decentralized SGD with Changing Topology and Local Updates, 2020,
https://arxiv.xilesou.top/abs/2003.10422

## Other Authors

* Dual Averaging for Distributed Optimization: Convergence Analysis and Network Scaling, 2011,
https://arxiv.xilesou.top/abs/1005.2012

* Towards Byzantine-resilient Learning in Decentralized Systems, 2020,
https://arxiv.xilesou.top/abs/2002.08569

* Asynchronous Accelerated Proximal Stochastic Gradient for Strongly Convex Distributed Finite Sums, 2019,
https://arxiv.xilesou.top/abs/1901.09865

* Decentralized Stochastic Optimization and Gossip Algorithms with Compressed Communication, 2019,
https://arxiv.xilesou.top/abs/1902.00340

* Proximity Without Consensus in Online Multiagent Optimization, 2016,
https://arxiv.xilesou.top/abs/1606.05578

* Hop: Heterogeneity-Aware Decentralized Training1606.05578, 2019,
https://arxiv.xilesou.top/abs/1902.01064

* DSA: Decentralized Double Stochastic Averaging Gradient Algorithm, 2016,
https://arxiv.xilesou.top/abs/1506.04216

**[â¬† Return to top](#contents)**
